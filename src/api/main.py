"""FastAPIä¸»åº”ç”¨"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import sys
import json

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.prediction.predictor import create_predictor
from src.api.routes.auth import router as auth_router
from src.api.routes.profile import router as profile_router
from src.api.routes.message import router as message_router
from src.utils.db_utils import DatabaseManager, get_db_manager
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="æ™ºèƒ½äº¤é€šæµé¢„æµ‹ç³»ç»Ÿ API",
    description="åŸºäºæ·±åº¦å­¦ä¹ çš„äº¤é€šæµé‡é¢„æµ‹æœåŠ¡",
    version="1.0.0"
)

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•ï¼ˆç”¨äºæä¾›å¤´åƒç­‰é™æ€èµ„æºï¼‰
static_dir = project_root / "static"
static_dir.mkdir(exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨
app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")

# é…ç½®CORSï¼ˆè·¨åŸŸèµ„æºå…±äº«ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        # æœ¬åœ°å¼€å‘ç¯å¢ƒ
        "http://127.0.0.1:5000",
        "http://localhost:5000",
        "http://127.0.0.1:8501",  # Streamlit
        "http://localhost:8501",
        # Sealos ç”Ÿäº§ç¯å¢ƒ
        "https://lybkgczezkpi.sealoshzh.site",  # å‰ç«¯åŸŸå
        "https://yjwkusxabeto.sealoshzh.site",  # åç«¯åŸŸå
        # Sealos æµ‹è¯•ç¯å¢ƒ
        "https://ukkmpvxeanxd.sealoshzh.site",  # å‰ç«¯æµ‹è¯•åœ°å€
        "https://hrhpdkpuwpxz.sealoshzh.site",  # åç«¯æµ‹è¯•åœ°å€
        "*"  # å…è®¸æ‰€æœ‰æ¥æºï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    ],
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰HTTPæ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)

# æ³¨å†Œè·¯ç”±
app.include_router(auth_router)
app.include_router(profile_router)
app.include_router(message_router)

# å…¨å±€é¢„æµ‹å™¨ï¼ˆå¯åŠ¨æ—¶åŠ è½½ï¼‰
predictor = None


class PredictionRequest(BaseModel):
    """é¢„æµ‹è¯·æ±‚"""
    sensor_id: str
    sequence_data: List[List[float]]  # shape: (seq_len, features)
    model_type: str = "lstm"


class PredictionResponse(BaseModel):
    """é¢„æµ‹å“åº”"""
    sensor_id: str
    flow_prediction: float
    density_prediction: float
    congestion_status: int
    congestion_level: str
    confidence: float
    prediction_time: str
    model_type: str


# ===================== åŸå¸‚çº§é¢„æµ‹ï¼ˆå…¨å›½ä¸»è¦åŸå¸‚ï¼‰ =====================
class CityPredictionRequest(BaseModel):
    city: str
    date: str
    time_range: str
    weather: str
    district: str | None = None
    other: str | None = None
    token: str | None = None  # æ·»åŠ tokenå­—æ®µï¼Œç”¨äºè¯†åˆ«ç”¨æˆ·
    model_type: str | None = None  # æ¨¡å‹ç±»å‹ï¼ˆä»ç”¨æˆ·é…ç½®è·å–ï¼‰


@app.post("/city/predict")
async def city_predict(req: CityPredictionRequest):
    """
    é¢å‘å…¨å›½ä¸»è¦åŸå¸‚çš„äº¤é€šæµé‡é¢„æµ‹ï¼ˆæ¼”ç¤ºç‰ˆï¼‰

    è¯´æ˜ï¼š
    - è¯¥æ¥å£ç»“åˆæ—¶é—´æ®µã€å¤©æ°”ã€åŠŸèƒ½åŒºç­‰è¦ç´ ç”Ÿæˆç¨³å®šå¯å¤ç°çš„æ¼”ç¤ºé¢„æµ‹ç»“æœ
    - åç»­å¯æ¥å…¥çœŸå®åŸå¸‚çº§æ•°æ®ä¸æ¨¡å‹
    """
    import hashlib
    import random
    import asyncio
    
    # æ¨¡æ‹Ÿæ¨¡å‹é¢„æµ‹å»¶è¿Ÿï¼ˆ3~6ç§’éšæœºï¼‰ï¼Œå¢å¼ºçœŸå®æ„Ÿ
    delay = random.uniform(3.0, 6.0)
    await asyncio.sleep(delay)

    # ç”Ÿæˆç¡®å®šæ€§éšæœºç§å­ï¼ˆåŸºäºè¾“å…¥ï¼‰
    seed_src = f"{req.city}|{req.date}|{req.time_range}|{req.weather}|{req.district}|{req.other}"
    seed_int = int(hashlib.sha256(seed_src.encode('utf-8')).hexdigest(), 16) % (2**32 - 1)
    rng = random.Random(seed_int)

    # åŸºç¡€æµé‡ï¼ˆä¸åŒåŸå¸‚è§„æ¨¡ä¸åŒçš„åŸºæ•°ï¼‰
    city_scale = {
        'åŒ—äº¬': 9800, 'ä¸Šæµ·': 9600, 'å¹¿å·': 8800, 'æ·±åœ³': 8600, 'æ­å·': 8200,
        'å—äº¬': 7600, 'è‹å·': 7400, 'å¤©æ´¥': 7200, 'æ­¦æ±‰': 8000, 'æˆéƒ½': 7900,
        'é‡åº†': 7800, 'è¥¿å®‰': 7000, 'éƒ‘å·': 6900, 'é’å²›': 6800, 'å¦é—¨': 6400,
        'å®æ³¢': 6600, 'åˆè‚¥': 6300, 'ä½›å±±': 6200, 'ä¸œè': 6100
    }
    base = city_scale.get(req.city, 6000)

    # æ—¶é—´æ®µå½±å“ç³»æ•°
    tr = req.time_range
    if 'æ—©é«˜å³°' in tr:
        time_k = 1.15
    elif 'æ™šé«˜å³°' in tr:
        time_k = 1.2
    elif 'å¤œé—´' in tr:
        time_k = 0.7
    else:
        time_k = 0.95

    # å¤©æ°”å½±å“ç³»æ•°
    weather_k = {
        'æ™´': 1.0, 'å¤šäº‘': 0.98, 'å°é›¨': 0.92, 'å¤§é›¨': 0.85, 'æš´é›ª': 0.75, 'é›¾éœ¾': 0.9, 'æ²™å°˜æš´': 0.8
    }.get(req.weather, 0.95)

    # åŠŸèƒ½åŒºå½±å“
    district_k = {
        'ä¸»åŸåŒº': 1.1, 'å•†åŠ¡åŒº': 1.12, 'é«˜æ ¡åŒº': 0.95, 'æ™¯åŒº': 1.05, 'ä½å®…åŒº': 0.9, 'å·¥ä¸šåŒº': 1.0, 'å…¶ä»–': 1.0
    }.get((req.district or 'å…¶ä»–'), 1.0)

    # éšæœºæ‰°åŠ¨ï¼ˆÂ±6%ï¼‰
    noise = 1.0 + (rng.random() - 0.5) * 0.12

    flow_per_hour = int(base * time_k * weather_k * district_k * noise)
    flow_per_hour = max(500, min(flow_per_hour, 15000))

    # ç½®ä¿¡åº¦ä¸æ‹¥å µç­‰çº§
    confidence = round(0.82 + (rng.random() * 0.1), 2)
    severity = 'ä¸¥é‡' if flow_per_hour > 11000 else ('æ‹¥å µ' if flow_per_hour > 8500 else ('ä¸€èˆ¬' if flow_per_hour > 6000 else 'ç•…é€š'))

    base_speed = 68 - (flow_per_hour / 15000) * 35 + rng.uniform(-4, 4)
    avg_speed = round(max(18.0, min(70.0, base_speed)), 1)

    severity_index_map = {
        'ä¸¥é‡': 0.88,
        'æ‹¥å µ': 0.68,
        'ä¸€èˆ¬': 0.48,
        'ç•…é€š': 0.22,
    }
    congestion_index = severity_index_map.get(severity, 0.45) + (rng.random() - 0.5) * 0.08
    congestion_index = round(max(0.05, min(congestion_index, 0.95)), 2)

    # å…¨å›½çœä»½äº¤é€šæµçƒ­åŠ›æ•°æ®ï¼ˆéµå¾ªä¸œå¤šè¥¿å°‘åŸåˆ™ï¼‰
    # ä½¿ç”¨EChartsæ ‡å‡†çš„çœä»½å…¨ç§°
    province_base_flows = {
        # ä¸œéƒ¨æ²¿æµ·å‘è¾¾åœ°åŒºï¼ˆé«˜æµé‡ï¼š10000-13000ï¼‰
        'åŒ—äº¬å¸‚': 12500, 'ä¸Šæµ·å¸‚': 12200, 'å¤©æ´¥å¸‚': 9500,
        'å¹¿ä¸œçœ': 11800, 'æ±Ÿè‹çœ': 10500, 'æµ™æ±Ÿçœ': 10200,
        'ç¦å»ºçœ': 8500, 'å±±ä¸œçœ': 9800,
        
        # ä¸­éƒ¨åœ°åŒºï¼ˆä¸­é«˜æµé‡ï¼š7000-9000ï¼‰
        'æ²³å—çœ': 8800, 'æ¹–åŒ—çœ': 8500, 'æ¹–å—çœ': 8200,
        'æ²³åŒ—çœ': 8000, 'å®‰å¾½çœ': 7500, 'æ±Ÿè¥¿çœ': 7200,
        'å±±è¥¿çœ': 6500,
        
        # ä¸œåŒ—åœ°åŒºï¼ˆä¸­ç­‰æµé‡ï¼š5000-7000ï¼‰
        'è¾½å®çœ': 7200, 'å‰æ—çœ': 5500, 'é»‘é¾™æ±Ÿçœ': 5800,
        
        # è¥¿å—åœ°åŒºï¼ˆä¸­ç­‰æµé‡ï¼š5000-8000ï¼‰
        'é‡åº†å¸‚': 8200, 'å››å·çœ': 8800, 'äº‘å—çœ': 6200,
        'è´µå·çœ': 5500, 'å¹¿è¥¿å£®æ—è‡ªæ²»åŒº': 6800,
        
        # è¥¿åŒ—åœ°åŒºï¼ˆä½æµé‡ï¼š2000-5000ï¼‰
        'é™•è¥¿çœ': 7000, 'ç”˜è‚ƒçœ': 4200, 'å®å¤å›æ—è‡ªæ²»åŒº': 3200,
        'é’æµ·çœ': 2500, 'æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº': 4000,
        'å†…è’™å¤è‡ªæ²»åŒº': 4500,
        
        # ç‰¹åˆ«è¡Œæ”¿åŒºå’Œå…¶ä»–
        'è¥¿è—è‡ªæ²»åŒº': 1800, 'æµ·å—çœ': 4800,
        'å°æ¹¾çœ': 7500, 'é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒº': 10500, 'æ¾³é—¨ç‰¹åˆ«è¡Œæ”¿åŒº': 5200
    }
    
    province_flows = []
    
    # åŸå¸‚åˆ°çœä»½çš„æ˜ å°„ï¼ˆä½¿ç”¨å®Œæ•´çœä»½åç§°ï¼‰
    city_province_map = {
        'åŒ—äº¬': 'åŒ—äº¬å¸‚', 'å¤©æ´¥': 'å¤©æ´¥å¸‚', 'ä¸Šæµ·': 'ä¸Šæµ·å¸‚', 'é‡åº†': 'é‡åº†å¸‚',
        'æ­å·': 'æµ™æ±Ÿçœ', 'å®æ³¢': 'æµ™æ±Ÿçœ', 'å—äº¬': 'æ±Ÿè‹çœ', 'è‹å·': 'æ±Ÿè‹çœ',
        'å¹¿å·': 'å¹¿ä¸œçœ', 'æ·±åœ³': 'å¹¿ä¸œçœ', 'ä½›å±±': 'å¹¿ä¸œçœ', 'ä¸œè': 'å¹¿ä¸œçœ',
        'æ­¦æ±‰': 'æ¹–åŒ—çœ', 'æˆéƒ½': 'å››å·çœ', 'è¥¿å®‰': 'é™•è¥¿çœ', 'éƒ‘å·': 'æ²³å—çœ',
        'é’å²›': 'å±±ä¸œçœ', 'å¦é—¨': 'ç¦å»ºçœ', 'åˆè‚¥': 'å®‰å¾½çœ'
    }
    
    for province, base in province_base_flows.items():
        # æ ¹æ®å½“å‰åŸå¸‚æ‰€åœ¨çœä»½å’Œæ—¶é—´æ®µè°ƒæ•´æµé‡
        province_flow = base
        
        # å¦‚æœæ˜¯é¢„æµ‹åŸå¸‚æ‰€åœ¨çœä»½ï¼Œæµé‡æ›´æ¥è¿‘é¢„æµ‹å€¼
        if city_province_map.get(req.city) == province:
            province_flow = int(flow_per_hour * rng.uniform(0.95, 1.15))
        else:
            # å…¶ä»–çœä»½æ ¹æ®æ—¶é—´æ®µè°ƒæ•´ï¼Œä¿æŒä¸œå¤šè¥¿å°‘çš„æ¢¯åº¦
            province_flow = int(base * time_k * weather_k * rng.uniform(0.85, 1.15))
        
        province_flows.append({
            'name': province,
            'value': max(800, min(15000, province_flow))
        })

    # å„åŸå¸‚çœŸå®äº¤é€šç›‘æ§ç‚¹ï¼ˆæ‰©å±•åˆ°24-32ä¸ªè·¯å£ï¼‰
    city_monitors = {
        'åŒ—äº¬': [
            'é•¿å®‰è¡—å¤©å®‰é—¨è·¯å£', 'ä¸‰ç¯å›½è´¸æ¡¥', 'äºŒç¯ä¸œç›´é—¨æ¡¥', 'å››ç¯æœ›äº¬æ¡¥', 'è¥¿äºŒç¯å¤å…´é—¨æ¡¥', 'ä¸œä¸‰ç¯å›½è´¸ç«‹äº¤', 
            'æœºåœºé«˜é€Ÿä¸‰å…ƒæ¡¥', 'äº¬é€šå¿«é€ŸåŒæ¡¥', 'äº”ç¯äº”æ£µæ¾æ¡¥', 'å…­ç¯æ²™æ²³æ¡¥', 'è¥¿ä¸‰ç¯ç´«ç«¹æ¡¥', 'ä¸œå››ç¯å››æƒ æ¡¥',
            'åŒ—ä¸‰ç¯å®‰è´æ¡¥', 'å—ä¸‰ç¯æœ¨æ¨¨å›­æ¡¥', 'äº¬æ‰¿é«˜é€Ÿæœ›äº¬', 'äº¬å¼€é«˜é€Ÿç‰æ³‰è¥', 'äº¬è—é«˜é€Ÿæ¸…æ²³', 'äº¬æ¸¯æ¾³é«˜é€Ÿè¥¿é“å£',
            'é˜œçŸ³è·¯é¦–é’¢', 'å¹¿æ¸ è·¯åŒäº•æ¡¥', 'æœé˜³è·¯å¤§æœ›è·¯', 'å¹³å®‰å¤§è¡—åœ°å®‰é—¨', 'å¾·èƒœé—¨æ¡¥', 'ç§¯æ°´æ½­æ¡¥'
        ],
        'ä¸Šæµ·': [
            'å—äº¬è·¯äººæ°‘å¹¿åœº', 'å»¶å®‰é«˜æ¶æˆéƒ½è·¯æ®µ', 'ä¸­ç¯æ¼•æºªè·¯ç«‹äº¤', 'å¤–ç¯æ²ªé—µé«˜æ¶', 'æµ¦ä¸œä¸–çºªå¤§é“', 'è™¹æ¡¥æ¢çº½',
            'å†…ç¯é«˜æ¶å¾å®¶æ±‡', 'åŒ—æ¨ªé€šé“', 'å—åŒ—é«˜æ¶å…±å’Œæ–°è·¯', 'å¢æµ¦å¤§æ¡¥æµ¦è¥¿', 'æ¨æµ¦å¤§æ¡¥', 'å¤–æ»©ä¸­å±±ä¸œä¸€è·¯',
            'æ·®æµ·è·¯é™•è¥¿å—è·¯', 'å››å·åŒ—è·¯è™¹å£', 'å¼ æ¨è·¯æµ¦ä¸œå—è·¯', 'é¾™é˜³è·¯ç£æ‚¬æµ®ç«™', 'å—äº¬è¥¿è·¯é™å®‰å¯º', 'ä¸­å±±å…¬å›­',
            'äº”è§’åœºå•†åœˆ', 'å¾å®¶æ±‡å•†åœˆ', 'æ‰“æµ¦æ¡¥', 'é²ç­è·¯', 'å¤§æŸæ ‘', 'æ›²é˜³è·¯'
        ],
        'å¹¿å·': [
            'å¤©æ²³è·¯ä½“è‚²ä¸­å¿ƒ', 'ç¯å¸‚è·¯æ·˜é‡‘ç«‹äº¤', 'å¹¿å·å¤§é“å®¢æ‘ç«‹äº¤', 'é»„åŸ”å¤§é“ç§‘éŸµè·¯å£', 'å†…ç¯è·¯åŠ¨ç‰©å›­å—é—¨', 'ç æ±Ÿæ–°åŸèŠ±åŸå¤§é“',
            'ç•ªç¦ºå¤§é“å—', 'ç™½äº‘å¤§é“', 'æ–°æ¸¯è·¯ç¶æ´²', 'æ±Ÿå—å¤§é“å—', 'ä¸œé£è·¯', 'ä¸­å±±è·¯',
            'åŒ—äº¬è·¯æ­¥è¡Œè¡—', 'ä¸Šä¸‹ä¹æ­¥è¡Œè¡—', 'äº”ç¾Šæ–°åŸ', 'èµ¤å²—ç«‹äº¤', 'æ´›æºªå¤§æ¡¥', 'æµ·ç æ¡¥',
            'äººæ°‘æ¡¥', 'è§£æ”¾æ¡¥', 'åå—å¿«é€Ÿå¹²çº¿', 'å¹¿å›­å¿«é€Ÿ', 'æœºåœºé«˜é€Ÿä¸‰å…ƒé‡Œ', 'ç¯åŸé«˜é€Ÿ'
        ],
        'æ·±åœ³': [
            'æ·±å—å¤§é“è½¦å…¬åº™', 'æ»¨æ²³å¤§é“é¦™èœœæ¹–', 'åŒ—ç¯å¤§é“æ¢…æ—å…³', 'å—å±±å¤§é“åæµ·', 'ç¦ç”°ä¸­å¿ƒåŒº', 'å®å®‰å¤§é“æ–°å®‰',
            'é¾™å²—å¤§é“å¸ƒå‰', 'ç›ç”°æ¸¯è¿›æ¸¯è·¯', 'æ·±å—å¤§é“ä¸–ç•Œä¹‹çª—', 'æ·±å—ä¸œè·¯è€è¡—', 'æ²™æ²³è¥¿è·¯', 'ä¾¨åŸä¸œè·¯',
            'ç§‘è‹‘è·¯', 'ç™½çŸ³è·¯', 'å¸ƒå¿ƒè·¯', 'ç¿ ç«¹è·¯', 'çº¢å²­è·¯', 'åå¼ºåŒ—',
            'çš‡å²—è·¯', 'æ–°æ´²è·¯', 'å‰æµ·è·¯', 'è›‡å£å·¥ä¸šåŒº', 'é¾™åå¤§é“', 'æ°‘æ²»å¤§é“'
        ],
        'æ­å·': [
            'è¥¿æºªè·¯é«˜å³°è·¯å£', 'å»¶å®‰è·¯æ­¦æ—å¹¿åœº', 'ä¸­æ²³é«˜æ¶å‡¤èµ·è·¯æ®µ', 'ç§‹æ¶›è·¯å¤å…´å¤§æ¡¥', 'æ»¨æ±Ÿæ»¨ç››è·¯å£', 'é’±å¡˜æ–°åŒºå¤§é“',
            'åŸè¥¿é“¶æ³°è·¯å£', 'ä¹‹æ±Ÿå¤§æ¡¥åŒ—ä¾§', 'è¥¿æ¹–éš§é“', 'ç´«é‡‘æ¸¯è·¯', 'æ–‡ä¸€è¥¿è·¯', 'å¤©ç›®å±±è·¯',
            'åº†æ˜¥è·¯', 'è§£æ”¾è·¯', 'æ¹–æ»¨å•†åœˆ', 'å´å±±å¹¿åœº', 'é’±æ±Ÿæ–°åŸ', 'å¥¥ä½“ä¸­å¿ƒ',
            'è§å±±æœºåœºé«˜é€Ÿ', 'é’±å¡˜æ±Ÿå¤§æ¡¥', 'å¤å…´å¤§æ¡¥', 'è¥¿å…´å¤§æ¡¥', 'ä¸‹æ²™é«˜æ•™å›­', 'ä½™æ­é«˜é“ç«™'
        ],
        'å—äº¬': [
            'æ–°è¡—å£æ´ªæ­¦è·¯', 'ä¸­å±±ä¸œè·¯æ€»ç»Ÿåºœ', 'ä¸­å¤®è·¯é¼“æ¥¼å¹¿åœº', 'åº”å¤©å¤§è¡—è½¯ä»¶å¤§é“', 'æ±Ÿä¸œè·¯æ‰¬å­æ±Ÿéš§é“', 'æ±‰ä¸­é—¨å¤§è¡—',
            'ç„æ­¦å¤§é“', 'å»ºé‚ºè·¯æ²³è¥¿CBD', 'å¤«å­åº™ç§¦æ·®æ²³', 'ä¸­åé—¨åŸå ¡', 'æ°´è¥¿é—¨å¤§è¡—', 'é¾™èŸ è·¯',
            'åŒ—äº¬ä¸œè·¯', 'å¤ªå¹³åŒ—è·¯', 'æ¹–å—è·¯ç‹®å­æ¡¥', 'ç æ±Ÿè·¯', 'ä»™æ—å¤§é“', 'æ±Ÿå®å¤§å­¦åŸ',
            'å—äº¬å—ç«™', 'ç¦„å£æœºåœºé«˜é€Ÿ', 'é•¿æ±Ÿå¤§æ¡¥', 'é•¿æ±Ÿä¸‰æ¡¥', 'æ‰¬å­æ±Ÿå¤§é“', 'æ²³è¥¿ä¸‡è¾¾'
        ],
        'è‹å·': [
            'è§‚å‰è¡—äººæ°‘è·¯å£', 'å¹²å°†è·¯è«é‚ªè·¯å£', 'ä¸œç¯è·¯æ˜Ÿæµ·å¹¿åœº', 'é‡‘é¸¡æ¹–å¤§é“', 'å·¥ä¸šå›­åŒºæ˜Ÿæ¸¯è¡—', 'ç‹®å±±è·¯æ–°åŒº',
            'å´ä¸­å¤§é“', 'ç›¸åŸå¤§é“', 'å¹³æ±Ÿè·¯å†å²è¡—åŒº', 'çŸ³è·¯å•†åœˆ', 'å›½é™…åšè§ˆä¸­å¿ƒ', 'åœ†èå¹¿åœº',
            'ç‹¬å¢…æ¹–å¤§é“', 'ç°ä»£å¤§é“', 'è‹è™¹è·¯', 'è‹å·åŒ—ç«™', 'é«˜é“æ–°åŸ', 'å¤ªæ¹–å¤§é“',
            'æœ¨æ¸å¤é•‡', 'è™ä¸˜å±±é—¨', 'ç•™å›­è·¯', 'æ‹™æ”¿å›­', 'æŠ¤åŸæ²³', 'å¹³é—¨'
        ],
        'å¤©æ´¥': [
            'å’Œå¹³è·¯æ»¨æ±Ÿé“', 'å—äº¬è·¯ä¸–çºªé’Ÿ', 'é»‘ç‰›åŸé“', 'å«å›½é“å¤©å¡”', 'è§£æ”¾å—è·¯', 'æµ·æ²³ä¸œè·¯',
            'æ²³ä¸œå¤§æ¡¥', 'æ´¥æ»¨å¤§é“', 'äº”å¤§é“', 'å¤æ–‡åŒ–è¡—', 'æ„å¼é£æƒ…åŒº', 'æ»¨æ±Ÿé“',
            'è¥¿åº·è·¯', 'å—å¼€å¤§å­¦', 'å¤©æ´¥å¤§å­¦', 'æ°´ä¸Šå…¬å›­', 'å¥¥ä½“ä¸­å¿ƒ', 'æ¢…æ±Ÿä¼šå±•ä¸­å¿ƒ',
            'å¤©æ´¥ç«™', 'å¤©æ´¥è¥¿ç«™', 'æ»¨æµ·æ–°åŒº', 'å¡˜æ²½å¤–æ»©', 'å¼€å‘åŒº', 'ç©ºæ¸¯ç»æµåŒº'
        ],
        'æ­¦æ±‰': [
            'ä¸­å±±å¤§é“æ±Ÿæ±‰è·¯', 'è§£æ”¾å¤§é“å¾ªç¤¼é—¨', 'çå–»è·¯è¡—é“å£', 'æ­¦æ˜Œå’Œå¹³å¤§é“', 'é•¿æ±Ÿå¤§æ¡¥æ­¦æ˜Œæ¡¥å¤´', 'äºŒä¸ƒé•¿æ±Ÿå¤§æ¡¥',
            'é¹¦é¹‰å¤§é“', 'å…‰è°·å¹¿åœº', 'æ­¦æ±‰å¤©åœ°', 'æ¥šæ²³æ±‰è¡—', 'æˆ·éƒ¨å··', 'æ±Ÿæ±‰è·¯æ­¥è¡Œè¡—',
            'æ±‰å£æ±Ÿæ»©', 'æ­¦æ˜Œæ±Ÿæ»©', 'é»„é¹¤æ¥¼', 'ä¸œæ¹–ç»¿é“', 'æ­¦æ±‰ç«™', 'æ±‰å£ç«™',
            'å…‰è°·å¹¿åœºè½¬ç›˜', 'å…³å±±å¤§é“', 'çå–»è·¯é²å··', 'é›„æ¥šå¤§é“', 'ç™½æ²™æ´²å¤§æ¡¥', 'å¤©å…´æ´²å¤§æ¡¥'
        ],
        'æˆéƒ½': [
            'å¤©åºœå¹¿åœºäººæ°‘å—è·¯', 'ä¸€ç¯è·¯è·³ä¼å¡”', 'äºŒç¯å»ºè®¾è·¯', 'é”¦æ±Ÿå¤§é“åˆæ±Ÿäº­', 'å¤©åºœå¤§é“ä¸–çºªåŸ', 'å‰‘å—å¤§é“å­µåŒ–å›­',
            'çº¢æ˜Ÿè·¯äºŒæ®µ', 'æ˜¥ç†™è·¯æ€»åºœè·¯å£', 'å¤ªå¤é‡Œ', 'å®½çª„å··å­', 'æ­¦ä¾¯ç¥ ', 'é”¦é‡Œå¤è¡—',
            'äººæ°‘å…¬å›­', 'æœç”«è‰å ‚', 'é’ç¾Šå®«', 'é‡‘æ²™é—å€', 'ä¸‰ç¯è·¯å¨‡å­ç«‹äº¤', 'å››ç¯è·¯',
            'åŒæµæœºåœºé«˜é€Ÿ', 'æˆæ¸©é‚›é«˜é€Ÿ', 'æˆçŒé«˜é€Ÿ', 'æˆç»µé«˜é€Ÿ', 'å¤©åºœæ–°åŒº', 'é«˜æ–°åŒº'
        ],
        'é‡åº†': [
            'è§£æ”¾ç¢‘é‚¹å®¹è·¯', 'è§‚éŸ³æ¡¥å•†åœˆ', 'å—åªä¸‡è¾¾å¹¿åœº', 'æ²™åªåä¸‰å³¡å¹¿åœº', 'æœå¤©é—¨é•¿æ±Ÿå¤§æ¡¥', 'æ¸ä¸­åŒºå¤§åª',
            'æ±ŸåŒ—å˜´ä¸­å¤®å•†åŠ¡åŒº', 'æ¨å®¶åª', 'ä¸¤è·¯å£', 'èœå›­å', 'çŸ³æ¡¥é“º', 'æ¨å®¶åª',
            'æ¸åŒ—é¾™æºª', 'å—å²¸å¼¹å­çŸ³', 'ä¹é¾™å¡ç›´æ¸¯å¤§é“', 'æ¸åŒ—æœºåœº', 'åŒ—ç¢šç¼™äº‘å±±', 'æ±Ÿæ´¥å‡ æ±Ÿ',
            'åƒå®é—¨å¤§æ¡¥', 'ä¸œæ°´é—¨å¤§æ¡¥', 'é¹…å…¬å²©å¤§æ¡¥', 'é»„èŠ±å›­å¤§æ¡¥', 'æå®¶æ²±å¤§æ¡¥', 'é©¬å®¶å²©'
        ],
        'è¥¿å®‰': [
            'é’Ÿæ¥¼å—å¤§è¡—', 'å°å¯¨åå­—', 'é«˜æ–°è·¯ç§‘æŠ€è·¯', 'åŒ—å¤§è¡—å®‰è¿œé—¨', 'é•¿å®‰è·¯é›å¡”è·¯å£', 'æœªå¤®è·¯å‡¤åŸäº”è·¯',
            'æ›²æ±Ÿæ–°åŒºèŠ™è“‰è·¯', 'è¥¿ä¸‰ç¯ä¸°é•è·¯', 'å¤§é›å¡”', 'é’Ÿæ¥¼', 'é¼“æ¥¼', 'å›æ°‘è¡—',
            'å¤§å”ä¸å¤œåŸ', 'å¤§æ˜å®«', 'è¥¿å®‰ç«™', 'è¥¿å®‰åŒ—ç«™', 'ç»ä¹è·¯', 'å¤ªåè·¯',
            'å‡¤åŸä¸€è·¯', 'é«˜æ–°å››è·¯', 'ç§‘æŠ€è·¯', 'ä¸ˆå…«è·¯', 'ç”µå­åŸ', 'çº¬äºŒè¡—'
        ],
        'éƒ‘å·': [
            'äºŒä¸ƒå¹¿åœº', 'èŠ±å›­è·¯å†œä¸šè·¯', 'ä¸­åŸè·¯æ¡æŸè·¯', 'é‡‘æ°´è·¯æœªæ¥è·¯', 'éƒ‘ä¸œæ–°åŒºCBD', 'åŒ—ä¸‰ç¯æ–‡åŒ–è·¯',
            'èˆªæµ·è·¯', 'ç´«è†å±±è·¯', 'ä¸œé£è·¯', 'å»ºè®¾è·¯', 'åµ©å±±è·¯', 'å¤§å­¦è·¯',
            'ç»ä¸‰è·¯', 'æœªæ¥è·¯', 'é»„æ²³è·¯', 'åŒ—ç¯è·¯', 'å—ä¸‰ç¯', 'è¥¿ä¸‰ç¯',
            'éƒ‘å·ä¸œç«™', 'éƒ‘å·ç«™', 'æ–°éƒ‘æœºåœºé«˜é€Ÿ', 'éƒ‘å¼€å¤§é“', 'éƒ‘æ°‘é«˜é€Ÿ', 'CBDå¦‚æ„æ¹–'
        ],
        'é’å²›': [
            'äº”å››å¹¿åœºé¦™æ¸¯è·¯', 'å°ä¸œå•†åœˆ', 'å¸‚å—åŒºä¸­å±±è·¯', 'ææ²§ä¸‡è¾¾', 'å´‚å±±åŒºç§¦å²­è·¯', 'é»„å²›åŒºé•¿æ±Ÿè·¯',
            'å³å¢¨è“è°·', 'åŸé˜³åŒºæ­£é˜³è·¯', 'æ ˆæ¡¥', 'å…«å¤§å…³', 'å¥¥å¸†ä¸­å¿ƒ', 'çŸ³è€äººæµ·æ°´æµ´åœº',
            'é¦™æ¸¯ä¸­è·¯', 'é—½æ±Ÿè·¯', 'å»¶å‰è·¯', 'è¾½é˜³è¥¿è·¯', 'æµ·å°”è·¯', 'æ·±åœ³è·¯',
            'å®å¤è·¯', 'åŠ²æ¾è·¯', 'ç¦å·è·¯', 'å—äº¬è·¯', 'é’å²›ç«™', 'é’å²›åŒ—ç«™'
        ],
        'å¦é—¨': [
            'æ€æ˜ä¸­å±±è·¯', 'æ¹–æ»¨å—è·¯', 'ä»™å²³è·¯æ¹–é‡Œ', 'é›†ç¾å¤§é“', 'ç¯å²›è·¯ä¼šå±•ä¸­å¿ƒ', 'æµ·æ²§å¤§æ¡¥',
            'ç¿”å®‰éš§é“', 'åŒå®‰ç¯åŸè·¯', 'é¼“æµªå±¿ç å¤´', 'æ›¾ååµ', 'ç™½åŸæ²™æ»©', 'æ¤°é£å¯¨',
            'SMå¹¿åœº', 'æ–‡ç¶', 'è²å‚', 'å•å', 'è½¯ä»¶å›­äºŒæœŸ', 'è§‚éŸ³å±±',
            'äº”ç¼˜æ¹¾', 'é›†ç¾å­¦æ‘', 'ææ—æ¹¾', 'é©¬éŠ®æ¹¾', 'ç¿”å®‰æ–°åŸ', 'æµ·æ²§æ–°åŸ'
        ],
        'å®æ³¢': [
            'å¤©ä¸€å¹¿åœº', 'é¼“æ¥¼æ²¿æ±Ÿä¸œè·¯', 'æ±ŸåŒ—ä¸‡è¾¾', 'é„å·ä¸­å…´è·¯', 'ä¸œéƒ¨æ–°åŸ', 'å®æ³¢å¤§å­¦å‘¨è¾¹',
            'åŒ—ä»‘æ¸¯åŒº', 'é•‡æµ·æ‹›å®å±±å¤§æ¡¥', 'æœˆæ¹–å…¬å›­', 'åŸéšåº™', 'è€å¤–æ»©', 'ä¸‰æ±Ÿå£',
            'ç¯åŸå—è·¯', 'ä¸­å±±ä¸œè·¯', 'è§£æ”¾è·¯', 'çµæ¡¥è·¯', 'ç™¾ä¸ˆè·¯', 'æ±Ÿä¸œåŒ—è·¯',
            'é„å·å¤§é“', 'ç¦æ˜è·¯', 'é¦–å—è·¯', 'å®å—è·¯', 'æ­ç”¬é«˜é€Ÿ', 'ç”¬å°æ¸©é«˜é€Ÿ'
        ],
        'åˆè‚¥': [
            'æ·®æ²³è·¯æ­¥è¡Œè¡—', 'é‡‘å¯¨è·¯é»„å±±è·¯å£', 'é•¿æ±Ÿè·¯èœ€å±±', 'åŒ…æ²³å¤§é“', 'æ”¿åŠ¡åŒºå¤©é¹…æ¹–', 'ç‘¶æµ·åŒºæ˜å…‰è·¯',
            'æ–°ç«™é«˜æ–°åŒº', 'æ»¨æ¹–æ–°åŒº', 'é€é¥æ´¥', 'åŒ…å…¬å›­', 'ä¸‰å­å£', 'å››ç‰Œæ¥¼',
            'èŠœæ¹–è·¯', 'å®¿å·è·¯', 'é˜œé˜³è·¯', 'è’™åŸè·¯', 'é•¿æ±Ÿä¸­è·¯', 'é©¬éå±±è·¯',
            'æœ›æ±Ÿè·¯', 'å¾½å·å¤§é“', 'åˆè‚¥å—ç«™', 'åˆè‚¥ç«™', 'æ–°æ¡¥æœºåœºé«˜é€Ÿ', 'é‡‘å¯¨å—è·¯é«˜æ¶'
        ],
        'ä½›å±±': [
            'ç¥–åº™è·¯', 'å­£åè·¯', 'é­å¥‡è·¯', 'å—æµ·å¤§é“', 'æ¡‚åŸåƒç¯æ¹–', 'é¡ºå¾·å¤§è‰¯',
            'ä¸‰æ°´å¹¿åœº', 'é«˜æ˜è·åŸ', 'å²­å—å¤§é“', 'ä½›å±±å¤§é“', 'æ±¾æ±Ÿè·¯', 'æ™®å›è·¯',
            'åŒæµè·¯', 'æ–‡åè·¯', 'ç¦…åŸä¸œæ–¹å¹¿åœº', 'å—åº„', 'å¼ æ§', 'çŸ³æ¹¾',
            'å¤§æ²¥', 'ç‹®å±±', 'è¥¿æ¨µå±±', 'é™ˆæ‘', 'å‹’æµ', 'å®¹æ¡‚'
        ],
        'ä¸œè': [
            'å—åŸé¸¿ç¦è·¯', 'ä¸œåŸèŠ±å›­è·¯', 'èå¤ªè·¯', 'è™é—¨å¤ªå¹³', 'é•¿å®‰æŒ¯å®‰è·¯', 'å¡˜å¦ç¯å¸‚è·¯',
            'åšè¡—å¤§é“', 'æ¾å±±æ¹–å¤§é“', 'è™é—¨å¤§æ¡¥', 'å¸¸å¹³', 'æ¨Ÿæœ¨å¤´', 'å¤§æœ—',
            'é»„æ±Ÿ', 'æ¸…æºª', 'å‡¤å²—', 'çŸ³é¾™', 'çŸ³æ’', 'ä¼çŸ³',
            'èŒ¶å±±', 'æ¨ªæ²¥', 'ä¸œå‘', 'æ¡¥å¤´', 'è°¢å²—', 'æœ›ç‰›å¢©'
        ]
    }
    
    # è·å–å¯¹åº”åŸå¸‚çš„æ‰€æœ‰ç›‘æ§ç‚¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤
    all_monitor_names = city_monitors.get(req.city, [
        'ä¸»å¹²é“ä¸€å·è·¯å£', 'æ ¸å¿ƒåŒºäºŒå·è·¯æ®µ', 'ç¯çº¿ä¸‰å·ç«‹äº¤', 'æ–°åŒºå››å·å¤§é“', 
        'æœºåœºäº”å·é«˜æ¶', 'å¼€å‘åŒºå…­å·è·¯', 'å•†åœˆä¸ƒå·è·¯å£', 'æ™¯åŒºå…«å·å¤§æ¡¥',
        'CBDä¹å·å¹¿åœº', 'é«˜æ–°åŒºåå·å¤§é“', 'ç«è½¦ç«™å¹¿åœº', 'æ±½è½¦ç«™è·¯å£',
        'ä½“è‚²ä¸­å¿ƒ', 'ä¼šå±•ä¸­å¿ƒ', 'æ”¿åŠ¡åŒº', 'å¤§å­¦åŸ', 'å·¥ä¸šå›­åŒº', 'ç‰©æµå›­',
        'ç§‘æŠ€å›­', 'ç»æµå¼€å‘åŒº', 'ä¿ç¨åŒº', 'è‡ªè´¸åŒº', 'æ–°åŸåŒº', 'è€åŸåŒº'
    ])
    
    # æ‰“ä¹±é¡ºåºå¹¶é€‰æ‹©å‰8ä¸ªï¼ˆä½¿ç”¨ç¡®å®šæ€§éšæœºï¼‰
    monitor_sample = rng.sample(all_monitor_names, min(8, len(all_monitor_names)))
    
    monitors = [{
        'name': f"{req.city}Â·{label}", 
        'status': rng.choice(['è‰¯å¥½','æ‹¥å µ','ç¼“è¡Œ'])
    } for label in monitor_sample]
    
    # åŒæ—¶è¿”å›æ‰€æœ‰ç›‘æ§ç‚¹ï¼Œç”¨äºå‰ç«¯åˆ·æ–°
    all_monitors = [{
        'name': f"{req.city}Â·{label}", 
        'status': rng.choice(['è‰¯å¥½','æ‹¥å µ','ç¼“è¡Œ'])
    } for label in all_monitor_names]

    generated_at = datetime.now()
    index_score = round(flow_per_hour / 15000 * 100, 2)

    # ä¿å­˜åˆ°æ•°æ®åº“
    try:
        prediction_date = datetime.strptime(req.date, "%Y-%m-%d").date()
    except ValueError:
        raise HTTPException(status_code=400, detail="æ—¥æœŸæ ¼å¼åº”ä¸ºYYYY-MM-DD")

    # ä»tokenä¸­è·å–user_id
    user_id = None
    user_model_type = req.model_type or 'lstm'  # é»˜è®¤ä½¿ç”¨lstm
    if req.token:
        try:
            from src.utils.auth import decode_access_token
            payload = decode_access_token(req.token)
            if payload:
                user_id = payload.get("user_id")
                # å¦‚æœè¯·æ±‚ä¸­æ²¡æœ‰æŒ‡å®šæ¨¡å‹ç±»å‹ï¼Œä»ç”¨æˆ·é…ç½®ä¸­è·å–
                if not req.model_type and user_id:
                    try:
                        from src.utils.db_utils import get_session
                        from src.models_db.user import User
                        session = get_session()
                        user = session.query(User).filter(User.id == user_id).first()
                        if user and user.model_type:
                            user_model_type = user.model_type
                        session.close()
                    except Exception as user_error:
                        print(f"[WARN] è·å–ç”¨æˆ·æ¨¡å‹é…ç½®å¤±è´¥: {user_error}")
        except Exception as token_error:
            print(f"[WARN] è§£ætokenå¤±è´¥: {token_error}")

    try:
        db = get_db_manager()
        db.create_city_prediction({
            "user_id": user_id,  # æ·»åŠ user_id
            "model_type": user_model_type,  # æ·»åŠ model_type
            "city": req.city,
            "prediction_date": prediction_date,
            "time_range": req.time_range,
            "weather": req.weather,
            "district": req.district,
            "other": req.other,
            "flow_per_hour": flow_per_hour,
            "avg_speed": avg_speed,
            "congestion_index": congestion_index,
            "severity": severity,
            "confidence": confidence,
            "index_score": index_score,
            "extra_payload": json.dumps(req.dict(), ensure_ascii=False),
            "created_at": generated_at,
        })
        
        # å¦‚æœæœ‰ç”¨æˆ·IDï¼Œæ›´æ–°ç”¨æˆ·çš„é¢„æµ‹æ¬¡æ•°
        if user_id:
            try:
                from src.utils.db_utils import get_session
                from src.models_db.user import User
                session = get_session()
                user = session.query(User).filter(User.id == user_id).first()
                if user:
                    user.prediction_count = (user.prediction_count or 0) + 1
                    session.commit()
                session.close()
            except Exception as update_error:
                print(f"[WARN] æ›´æ–°ç”¨æˆ·é¢„æµ‹æ¬¡æ•°å¤±è´¥: {update_error}")
    except Exception as db_error:
        print(f"[WARN] ä¿å­˜åŸå¸‚é¢„æµ‹è®°å½•å¤±è´¥: {db_error}")

    return {
        'city': req.city,
        'flow_per_hour': flow_per_hour,
        'confidence': confidence,
        'severity': severity,
        'avg_speed': avg_speed,
        'congestion_index': congestion_index,
        'index_score': index_score,
        'province_flows': province_flows,
        'monitors': monitors,
        'all_monitors': all_monitors,  # æ‰€æœ‰ç›‘æ§ç‚¹ï¼Œç”¨äºå‰ç«¯åˆ·æ–°
        'generated_at': generated_at.strftime('%Y-%m-%d %H:%M:%S')
    }


@app.get("/city/history/summary")
async def city_history_summary(token: str, range_days: int = 0, city: str | None = None):
    """å†å²é¢„æµ‹æ±‡æ€»ç»Ÿè®¡ï¼ˆä»…è¿”å›å½“å‰ç”¨æˆ·çš„æ•°æ®ï¼‰"""
    from src.utils.auth import decode_access_token
    
    # éªŒè¯tokenå¹¶è·å–ç”¨æˆ·ID
    payload = decode_access_token(token)
    if not payload:
        raise HTTPException(status_code=401, detail="ä»¤ç‰Œæ— æ•ˆæˆ–å·²è¿‡æœŸ")
    
    user_id = payload.get("user_id")
    if not user_id:
        raise HTTPException(status_code=401, detail="ä»¤ç‰Œæ•°æ®æ— æ•ˆ")
    
    try:
        # åªè¿”å›å½“å‰ç”¨æˆ·çš„ç»Ÿè®¡æ•°æ®
        stats = get_db_manager().get_city_prediction_stats(
            user_id=user_id,  # æ·»åŠ ç”¨æˆ·IDè¿‡æ»¤
            range_days=range_days, 
            city=city
        )
        return stats
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")


@app.get("/city/history/records")
async def city_history_records(token: str, limit: int = 100, range_days: int = 0, city: str | None = None):
    """å†å²é¢„æµ‹è®°å½•åˆ—è¡¨ï¼ˆä»…è¿”å›å½“å‰ç”¨æˆ·çš„æ•°æ®ï¼‰"""
    from src.utils.auth import decode_access_token
    
    # éªŒè¯tokenå¹¶è·å–ç”¨æˆ·ID
    payload = decode_access_token(token)
    if not payload:
        raise HTTPException(status_code=401, detail="ä»¤ç‰Œæ— æ•ˆæˆ–å·²è¿‡æœŸ")
    
    user_id = payload.get("user_id")
    if not user_id:
        raise HTTPException(status_code=401, detail="ä»¤ç‰Œæ•°æ®æ— æ•ˆ")
    
    try:
        # åªè¿”å›å½“å‰ç”¨æˆ·çš„é¢„æµ‹è®°å½•
        records = get_db_manager().get_city_predictions(
            user_id=user_id,  # æ·»åŠ ç”¨æˆ·IDè¿‡æ»¤
            limit=limit,
            range_days=range_days,
            city=city,
        )
        return {
            "count": len(records),
            "records": records,
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å†å²è®°å½•å¤±è´¥: {str(e)}")


@app.get("/city/history/detail/{record_id}")
async def city_history_detail(record_id: int, token: str):
    """è·å–å•æ¡å†å²é¢„æµ‹è®°å½•çš„è¯¦ç»†ä¿¡æ¯ï¼ˆéœ€è¦éªŒè¯æ˜¯å½“å‰ç”¨æˆ·çš„è®°å½•ï¼‰"""
    from src.utils.auth import decode_access_token
    
    # éªŒè¯tokenå¹¶è·å–ç”¨æˆ·ID
    payload = decode_access_token(token)
    if not payload:
        raise HTTPException(status_code=401, detail="ä»¤ç‰Œæ— æ•ˆæˆ–å·²è¿‡æœŸ")
    
    user_id = payload.get("user_id")
    if not user_id:
        raise HTTPException(status_code=401, detail="ä»¤ç‰Œæ•°æ®æ— æ•ˆ")
    
    try:
        db = get_db_manager()
        record = db.get_city_prediction_by_id(record_id)
        
        if not record:
            raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
        
        # éªŒè¯è®°å½•æ˜¯å¦å±äºå½“å‰ç”¨æˆ·ï¼ˆé‡è¦ï¼šé˜²æ­¢è¶Šæƒè®¿é—®ï¼‰
        if record.get('user_id') != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤è®°å½•")
        
        # è§£æ extra_payload è·å–å®Œæ•´çš„é¢„æµ‹ä¿¡æ¯
        import json
        try:
            payload = json.loads(record.get('extra_payload', '{}'))
        except:
            payload = {}
        
        # é‡æ–°ç”Ÿæˆçœä»½æµé‡å’Œç›‘æ§ç‚¹æ•°æ®ï¼ˆåŸºäºåŸå§‹è¾“å…¥ï¼‰
        import hashlib
        import random
        
        city = record['city']
        date_str = str(record['prediction_date'])
        time_range = record['time_range']
        weather = payload.get('weather', 'æ™´')
        district = record.get('district', 'å…¶ä»–')
        
        # ä½¿ç”¨ç›¸åŒçš„ç§å­ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
        seed_src = f"{city}|{date_str}|{time_range}|{weather}|{district}"
        seed_int = int(hashlib.sha256(seed_src.encode('utf-8')).hexdigest(), 16) % (2**32 - 1)
        rng = random.Random(seed_int)
        
        # ç”Ÿæˆç›‘æ§ç‚¹æ•°æ®ï¼ˆéšæœº4ä¸ªï¼‰
        city_monitors = {
            'åŒ—äº¬': ['é•¿å®‰è¡—å¤©å®‰é—¨è·¯å£', 'ä¸‰ç¯å›½è´¸æ¡¥', 'äºŒç¯ä¸œç›´é—¨æ¡¥', 'å››ç¯æœ›äº¬æ¡¥', 'è¥¿äºŒç¯å¤å…´é—¨æ¡¥', 'ä¸œä¸‰ç¯å›½è´¸ç«‹äº¤', 'æœºåœºé«˜é€Ÿä¸‰å…ƒæ¡¥', 'äº¬é€šå¿«é€ŸåŒæ¡¥'],
            'ä¸Šæµ·': ['å—äº¬è·¯äººæ°‘å¹¿åœº', 'å»¶å®‰é«˜æ¶æˆéƒ½è·¯æ®µ', 'ä¸­ç¯æ¼•æºªè·¯ç«‹äº¤', 'å¤–ç¯æ²ªé—µé«˜æ¶', 'æµ¦ä¸œä¸–çºªå¤§é“', 'è™¹æ¡¥æ¢çº½', 'å†…ç¯é«˜æ¶å¾å®¶æ±‡', 'åŒ—æ¨ªé€šé“'],
            'å¹¿å·': ['å¤©æ²³è·¯ä½“è‚²ä¸­å¿ƒ', 'ç¯å¸‚è·¯æ·˜é‡‘ç«‹äº¤', 'å¹¿å·å¤§é“å®¢æ‘ç«‹äº¤', 'é»„åŸ”å¤§é“ç§‘éŸµè·¯å£', 'å†…ç¯è·¯åŠ¨ç‰©å›­å—é—¨', 'ç æ±Ÿæ–°åŸèŠ±åŸå¤§é“', 'ç•ªç¦ºå¤§é“å—', 'ç™½äº‘å¤§é“'],
            'æ·±åœ³': ['æ·±å—å¤§é“è½¦å…¬åº™', 'æ»¨æ²³å¤§é“é¦™èœœæ¹–', 'åŒ—ç¯å¤§é“æ¢…æ—å…³', 'å—å±±å¤§é“åæµ·', 'ç¦ç”°ä¸­å¿ƒåŒº', 'å®å®‰å¤§é“æ–°å®‰', 'é¾™å²—å¤§é“å¸ƒå‰', 'ç›ç”°æ¸¯è¿›æ¸¯è·¯'],
            'æ­å·': ['è¥¿æºªè·¯é«˜å³°è·¯å£', 'å»¶å®‰è·¯æ­¦æ—å¹¿åœº', 'ä¸­æ²³é«˜æ¶å‡¤èµ·è·¯æ®µ', 'ç§‹æ¶›è·¯å¤å…´å¤§æ¡¥', 'æ»¨æ±Ÿæ»¨ç››è·¯å£', 'é’±å¡˜æ–°åŒºå¤§é“', 'åŸè¥¿é“¶æ³°è·¯å£', 'ä¹‹æ±Ÿå¤§æ¡¥åŒ—ä¾§'],
            'å—äº¬': ['æ–°è¡—å£æ´ªæ­¦è·¯', 'ä¸­å±±ä¸œè·¯æ€»ç»Ÿåºœ', 'ä¸­å¤®è·¯é¼“æ¥¼å¹¿åœº', 'åº”å¤©å¤§è¡—è½¯ä»¶å¤§é“', 'æ±Ÿä¸œè·¯æ‰¬å­æ±Ÿéš§é“', 'æ±‰ä¸­é—¨å¤§è¡—', 'ç„æ­¦å¤§é“', 'å»ºé‚ºè·¯æ²³è¥¿CBD'],
            'æ­¦æ±‰': ['ä¸­å±±å¤§é“æ±Ÿæ±‰è·¯', 'è§£æ”¾å¤§é“å¾ªç¤¼é—¨', 'çå–»è·¯è¡—é“å£', 'æ­¦æ˜Œå’Œå¹³å¤§é“', 'é•¿æ±Ÿå¤§æ¡¥æ­¦æ˜Œæ¡¥å¤´', 'äºŒä¸ƒé•¿æ±Ÿå¤§æ¡¥', 'é¹¦é¹‰å¤§é“', 'å…‰è°·å¹¿åœº'],
            'æˆéƒ½': ['å¤©åºœå¹¿åœºäººæ°‘å—è·¯', 'ä¸€ç¯è·¯è·³ä¼å¡”', 'äºŒç¯å»ºè®¾è·¯', 'é”¦æ±Ÿå¤§é“åˆæ±Ÿäº­', 'å¤©åºœå¤§é“ä¸–çºªåŸ', 'å‰‘å—å¤§é“å­µåŒ–å›­', 'çº¢æ˜Ÿè·¯äºŒæ®µ', 'æ˜¥ç†™è·¯æ€»åºœè·¯å£'],
        }
        
        monitor_names = city_monitors.get(city, ['ä¸»å¹²é“è·¯å£', 'æ ¸å¿ƒåŒºè·¯æ®µ', 'ç¯çº¿ç«‹äº¤', 'æ–°åŒºå¤§é“', 'æœºåœºé«˜æ¶', 'å¼€å‘åŒºè·¯', 'å•†åœˆè·¯å£', 'æ™¯åŒºå¤§æ¡¥'])
        # éšæœºé€‰æ‹©4ä¸ªç›‘æ§ç‚¹
        selected_names = rng.sample(monitor_names, min(4, len(monitor_names)))
        monitors = [{
            'name': f"{city}Â·{name}",
            'status': rng.choice(['è‰¯å¥½', 'æ‹¥å µ', 'ç¼“è¡Œ'])
        } for name in selected_names]
        
        return {
            'id': record['id'],
            'city': city,
            'prediction_date': date_str,
            'time_range': time_range,
            'weather': weather,
            'district': district,
            'flow_per_hour': record['flow_per_hour'],
            'avg_speed': float(record['avg_speed']),
            'congestion_index': float(record['congestion_index']),
            'severity': record['severity'],
            'confidence': float(record['confidence']),
            'index_score': float(record['index_score']),
            'monitors': monitors,
            'created_at': str(record['created_at']),
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")


@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“å’ŒåŠ è½½æ¨¡å‹"""
    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    try:
        print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        db_manager = DatabaseManager()
        print("âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸  æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å¤±è´¥: {e}")
        print("   è¯·æ£€æŸ¥MySQLæœåŠ¡æ˜¯å¦è¿è¡Œ")
    
    # åŠ è½½é¢„æµ‹æ¨¡å‹
    global predictor
    try:
        print("ğŸ”„ æ­£åœ¨åŠ è½½é¢„æµ‹æ¨¡å‹...")
        predictor = create_predictor('lstm')
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸  æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("   è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼špython src/scripts/train_model.py")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "æ™ºèƒ½äº¤é€šæµé¢„æµ‹ç³»ç»Ÿ API",
        "version": "1.0.0",
        "status": "running" if predictor else "model_not_loaded",
        "docs": "/docs"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "model_loaded": predictor is not None,
        "timestamp": datetime.now().isoformat()
    }


@app.get("/predict/demo")
async def predict_demo(sensor_id: str = None, model_type: str = "lstm"):
    """
    æ¼”ç¤ºé¢„æµ‹ - ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡Œé¢„æµ‹
    
    å‚æ•°ï¼š
    - sensor_id: ä¼ æ„Ÿå™¨IDï¼ˆå¯é€‰ï¼Œæ ¼å¼å¦‚ "sensor_001"ï¼‰ï¼Œä¸æŒ‡å®šåˆ™éšæœºé€‰æ‹©
    - model_type: æ¨¡å‹ç±»å‹ lstm/gruï¼ˆé»˜è®¤lstmï¼‰
    """
    from src.utils.data_sampler import get_real_data_sampler
    import random
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
    global predictor
    if predictor is None:
        try:
            predictor = create_predictor(model_type)
        except Exception as e:
            raise HTTPException(
                status_code=503, 
                detail=f"æ¨¡å‹æœªåŠ è½½æˆ–ä¸å­˜åœ¨ã€‚è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼špython src/scripts/train_model.pyã€‚é”™è¯¯: {str(e)}"
            )
    
    try:
        # è·å–çœŸå®æ•°æ®é‡‡æ ·å™¨
        sampler = get_real_data_sampler()
        
        # è§£æä¼ æ„Ÿå™¨ID - å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª
        sensor_idx = None
        if sensor_id and sensor_id.startswith("sensor_"):
            try:
                sensor_idx = int(sensor_id.split("_")[1])
            except:
                pass
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šä¼ æ„Ÿå™¨ï¼Œä»å¤šä¸ªä¼ æ„Ÿå™¨ä¸­éšæœºé€‰æ‹©
        if sensor_idx is None:
            # ä»307ä¸ªä¼ æ„Ÿå™¨ä¸­éšæœºé€‰æ‹©ä¸€ä¸ª
            sensor_idx = random.randint(0, 306)
        
        # ä»çœŸå®æ•°æ®ä¸­é‡‡æ ·
        sequence_data, actual_sensor_idx, time_idx = sampler.sample_sequence(
            lookback=12,
            sensor_id=sensor_idx
        )
        
        # è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆç”¨äºJSONè¿”å›ï¼‰
        sequence_list = sequence_data.tolist()
        
        # ç”Ÿæˆä¼ æ„Ÿå™¨IDå­—ç¬¦ä¸²
        sensor_id_str = f"sensor_{actual_sensor_idx:03d}"
        
        # è¿›è¡Œé¢„æµ‹ï¼ˆä½¿ç”¨save_to_db=Trueè®©predictorè‡ªåŠ¨ä¿å­˜ï¼‰
        result = predictor.predict(
            input_data=sequence_data,
            sensor_id=sensor_id_str,
            save_to_db=True,
            target_time=datetime.now() + timedelta(hours=1)
        )
        
        # è·å–ä¼ æ„Ÿå™¨ç»Ÿè®¡ä¿¡æ¯
        stats = sampler.get_sensor_statistics(actual_sensor_idx)
        
        # è¿”å›ç»“æœ
        return {
            "sensor_id": sensor_id_str,
            "sensor_index": actual_sensor_idx,
            "time_index": int(time_idx),
            "flow_prediction": result['flow'],
            "density_prediction": result['density'],
            "congestion_status": result['congestion_status'],
            "congestion_level": result['congestion_level'],
            "confidence": result.get('confidence', 0.85),
            "prediction_time": datetime.now().isoformat(),
            "model_type": model_type,
            "input_data": sequence_list,  # è¿”å›çœŸå®çš„è¾“å…¥æ•°æ®
            "data_source": "PeMS04_Real_Data",  # æ ‡è¯†ä½¿ç”¨çœŸå®æ•°æ®
            "sensor_stats": stats  # ä¼ æ„Ÿå™¨ç»Ÿè®¡ä¿¡æ¯
        }
        
    except FileNotFoundError as e:
        raise HTTPException(
            status_code=503,
            detail=f"æ•°æ®é›†æœªæ‰¾åˆ°ã€‚è¯·å…ˆä¸‹è½½æ•°æ®é›†ï¼špython src/scripts/download_data.pyã€‚é”™è¯¯: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é¢„æµ‹å¤±è´¥: {str(e)}")


@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """
    äº¤é€šæµé¢„æµ‹æ¥å£
    
    è¯·æ±‚ç¤ºä¾‹ï¼š
    {
        "sensor_id": "sensor_001",
        "sequence_data": [[100.5, 60.2, 0.5], [102.3, 61.0, 0.52], ...],
        "model_type": "lstm"
    }
    """
    if predictor is None:
        raise HTTPException(
            status_code=503,
            detail="æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹"
        )
    
    try:
        # è½¬æ¢è¾“å…¥æ•°æ®
        input_data = np.array(request.sequence_data)
        
        # é¢„æµ‹
        result = predictor.predict(input_data)
        
        # æ„é€ å“åº”
        response = PredictionResponse(
            sensor_id=request.sensor_id,
            flow_prediction=result['flow'],
            density_prediction=result['density'],
            congestion_status=result['congestion_status'],
            congestion_level=result['congestion_level'],
            confidence=result['confidence'],
            prediction_time=result['prediction_time'],
            model_type=result['model_type']
        )
        
        return response
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é¢„æµ‹å¤±è´¥: {str(e)}")


@app.post("/predict/batch")
async def predict_batch(requests: List[PredictionRequest]):
    """
    æ‰¹é‡é¢„æµ‹æ¥å£
    
    è¯·æ±‚ç¤ºä¾‹ï¼š
    [
        {
            "sensor_id": "sensor_001",
            "sequence_data": [[100.5, 60.2, 0.5], ...],
            "model_type": "lstm"
        },
        ...
    ]
    """
    if predictor is None:
        raise HTTPException(
            status_code=503,
            detail="æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹"
        )
    
    try:
        results = []
        for req in requests:
            input_data = np.array(req.sequence_data)
            result = predictor.predict(
                input_data, 
                sensor_id=req.sensor_id,
                save_to_db=True
            )
            
            results.append(PredictionResponse(
                sensor_id=req.sensor_id,
                flow_prediction=result['flow'],
                density_prediction=result['density'],
                congestion_status=result['congestion_status'],
                congestion_level=result['congestion_level'],
                confidence=result['confidence'],
                prediction_time=result['prediction_time'],
                model_type=result['model_type']
            ))
        
        return results
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡é¢„æµ‹å¤±è´¥: {str(e)}")


@app.get("/history/{sensor_id}")
async def get_prediction_history(
    sensor_id: str,
    limit: int = 100
):
    """
    æŸ¥è¯¢æŒ‡å®šä¼ æ„Ÿå™¨çš„å†å²é¢„æµ‹è®°å½•
    
    å‚æ•°ï¼š
    - sensor_id: ä¼ æ„Ÿå™¨ID
    - limit: è¿”å›è®°å½•æ•°ï¼ˆé»˜è®¤100ï¼‰
    """
    try:
        from src.utils.db_utils import get_db_manager
        db = get_db_manager()
        
        records = db.get_predictions_by_sensor(
            sensor_id=sensor_id,
            limit=limit
        )
        
        return {
            "sensor_id": sensor_id,
            "count": len(records),
            "records": records
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@app.get("/history/recent")
async def get_recent_predictions(limit: int = 50):
    """
    è·å–æœ€è¿‘çš„é¢„æµ‹è®°å½•
    
    å‚æ•°ï¼š
    - limit: è¿”å›è®°å½•æ•°ï¼ˆé»˜è®¤50ï¼‰
    """
    try:
        from src.utils.db_utils import get_db_manager
        db = get_db_manager()
        
        try:
            records = db.get_recent_predictions(limit=limit)
        except Exception as db_error:
            # æ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œè¿”å›ç©ºæ•°æ®
            print(f"[ERROR] æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {db_error}")
            import traceback
            traceback.print_exc()
            return {
                "count": 0,
                "records": [],
                "error": "æ•°æ®åº“æš‚æ— æ•°æ®æˆ–è¿æ¥å¤±è´¥"
            }
        
        return {
            "count": len(records),
            "records": records
        }
    
    except Exception as e:
        # è¿”å›ç©ºæ•°æ®è€Œä¸æ˜¯500é”™è¯¯
        print(f"[ERROR] æŸ¥è¯¢å†å²è®°å½•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "count": 0,
            "records": [],
            "error": f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
        }


@app.post("/model/switch/{model_name}")
async def switch_model(model_name: str):
    """
    åˆ‡æ¢é¢„æµ‹æ¨¡å‹
    
    å‚æ•°ï¼š
    - model_name: æ¨¡å‹åç§°ï¼ˆlstm æˆ– gruï¼‰
    """
    global predictor
    
    if model_name.lower() not in ['lstm', 'gru']:
        raise HTTPException(
            status_code=400,
            detail="ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹ï¼Œä»…æ”¯æŒ lstm æˆ– gru"
        )
    
    try:
        predictor = create_predictor(model_name.lower())
        return {
            "message": f"æˆåŠŸåˆ‡æ¢åˆ° {model_name.upper()} æ¨¡å‹",
            "current_model": model_name.upper()
        }
    
    except FileNotFoundError:
        raise HTTPException(
            status_code=404,
            detail=f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_name}_best.pthï¼Œè¯·å…ˆè®­ç»ƒè¯¥æ¨¡å‹"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"åˆ‡æ¢æ¨¡å‹å¤±è´¥: {str(e)}"
        )


@app.get("/models")
async def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    from src.utils.config import config
    models_dir = Path(config.get('paths.models_best'))
    
    available_models = []
    if models_dir.exists():
        for model_file in models_dir.glob('*.pth'):
            available_models.append(model_file.stem.replace('_best', ''))
    
    return {
        "available_models": available_models,
        "current_model": predictor.model_type.upper() if predictor else None
    }


@app.get("/training/history")
async def get_training_history(limit: int = 10):
    """
    è·å–è®­ç»ƒå†å²è®°å½•
    
    å‚æ•°ï¼š
    - limit: è¿”å›è®°å½•æ•°ï¼ˆé»˜è®¤10ï¼‰
    """
    try:
        from src.utils.db_utils import get_db_manager
        db = get_db_manager()
        
        records = db.get_training_history(limit=limit)
        
        return {
            "count": len(records),
            "records": records
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@app.get("/stats/summary")
async def get_system_stats():
    """
    è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
    """
    try:
        from src.utils.db_utils import get_db_manager
        db = get_db_manager()
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        try:
            recent_predictions = db.get_recent_predictions(limit=1000)
        except Exception as e:
            print(f"[ERROR] è·å–é¢„æµ‹è®°å½•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            recent_predictions = []
        
        try:
            training_records = db.get_training_history(limit=100)
        except Exception as e:
            print(f"[ERROR] è·å–è®­ç»ƒè®°å½•å¤±è´¥: {e}")
            training_records = []
        
        # è®¡ç®—ç»Ÿè®¡
        total_predictions = len(recent_predictions)
        
        # æ‹¥å µçŠ¶æ€åˆ†å¸ƒ
        congestion_stats = {0: 0, 1: 0, 2: 0, 3: 0}
        for pred in recent_predictions:
            status = pred.get('congestion_prediction', 0)
            if status in congestion_stats:
                congestion_stats[status] += 1
        
        return {
            "total_predictions": total_predictions,
            "total_training_runs": len(training_records),
            "congestion_distribution": {
                "ç•…é€š": congestion_stats[0],
                "æ­£å¸¸": congestion_stats[1],
                "æ‹¥å µ": congestion_stats[2],
                "ä¸¥é‡æ‹¥å µ": congestion_stats[3]
            },
            "model_info": {
                "current_model": predictor.model_type.upper() if predictor else "æœªåŠ è½½",
                "device": str(predictor.device) if predictor else "N/A"
            }
        }
    
    except Exception as e:
        # è¿”å›é»˜è®¤å€¼è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        return {
            "total_predictions": 0,
            "total_training_runs": 0,
            "congestion_distribution": {
                "ç•…é€š": 0,
                "æ­£å¸¸": 0,
                "æ‹¥å µ": 0,
                "ä¸¥é‡æ‹¥å µ": 0
            },
            "model_info": {
                "current_model": predictor.model_type.upper() if predictor else "æœªåŠ è½½",
                "device": str(predictor.device) if predictor else "N/A"
            },
            "error": f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {str(e)}"
        }


if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ å¯åŠ¨FastAPIæœåŠ¡...")
    print("   è®¿é—® http://127.0.0.1:8000/docs æŸ¥çœ‹APIæ–‡æ¡£")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)

